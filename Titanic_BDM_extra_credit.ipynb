{"cells":[{"cell_type":"markdown","source":["# Titanic : Machine Learning From Disaster | Kaggle\n*Resources:\nhttps://www.kaggle.com/c/titanic\n*Data:\nhttps://www.kaggle.com/c/titanic/data"],"metadata":{}},{"cell_type":"markdown","source":["# Objective\n* Use Machine Learning to analyse the probability of the death of a person based on his/her gender, social-class, age and other factors"],"metadata":{}},{"cell_type":"code","source":["%sh\nwget \"https://dl.dropboxusercontent.com/s/ijmml65yga12urf/train.csv?dl=0\"  -O titanic_train.csv"],"metadata":{},"outputs":[],"execution_count":3},{"cell_type":"code","source":["# read in file using csv format\ntrain_df = spark.read.load('file:/databricks/driver/titanic_train.csv',\n                    format='com.databricks.spark.csv', \n                    header='true',\n                    inferSchema='true')\n# show 20 rows\ndisplay(train_df)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["train_df.registerTempTable(\"Titanic_train\")"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["%sql\nselect * from Titanic_train"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["%sql\nselect * from Titanic_train"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["%sql\nSELECT Survived,Sex,\nsum(CASE WHEN Age>= 0 AND Age < 20 THEN 1 END) AS  A0to20,\nsum(CASE WHEN Age>= 20 AND Age < 40 THEN 1 END) AS A20to40,\nsum(CASE WHEN Age>= 40 AND Age < 60 THEN 1 END) AS A40to60,\nsum(CASE WHEN Age>= 60 AND Age < 80 THEN 1 END) AS A60to80,\nsum(CASE WHEN Age>= 80 THEN 1 END) AS A80\nFROM Titanic_train as Agegroups\ngroup by Survived, Sex\n"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"code","source":[" from pyspark.ml import Pipeline\n from pyspark.ml.classification import LogisticRegression\n from pyspark.ml.feature import HashingTF, Tokenizer\n from pyspark.sql import Row\n from pyspark.sql.functions import UserDefinedFunction\n from pyspark.sql.types import *"],"metadata":{},"outputs":[],"execution_count":9},{"cell_type":"code","source":["# Convert results for working with MLlib input, which requires labels as a float\ndef labelForResults(s):\n     if s == 0:\n         return 0.0\n     else:\n         return 1.0\nlabel = UserDefinedFunction(labelForResults, DoubleType())\nlabeledData = train_df.select(label(train_df.Survived).alias('label'), train_df.Sex)\nlabeledData.take(1)"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":["# Data Transformation"],"metadata":{}},{"cell_type":"code","source":["# Remove nulls (could change to empty string)\nlabeledData = labeledData.filter(labeledData.label.isNotNull()).cache()\ntrain, test = labeledData.randomSplit([0.9, 0.1], seed=12345)"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["# Configuration of Pipeline"],"metadata":{}},{"cell_type":"code","source":["# Configure an ML pipeline, which consists of three stages: tokenizer, hashingTF, and lr.\ntokenizer = Tokenizer(inputCol=\"Sex\", outputCol=\"w\")\nhashingTF = HashingTF(inputCol=tokenizer.getOutputCol(), outputCol=\"features\")\nlr = LogisticRegression(maxIter=10, regParam=0.01)\npipeline = Pipeline(stages=[tokenizer, hashingTF, lr])\n\n# Fit the pipeline to training documents.\nmodel = pipeline.fit(train)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":["# Making predictions on test data"],"metadata":{}},{"cell_type":"code","source":["# Make predictions on test data.\npredictionsDf = model.transform(test)\npredictionsDf.registerTempTable('Predictions')\ndisplay(predictionsDf)"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["# Checking model accuracy"],"metadata":{}},{"cell_type":"code","source":["numSuccesses = predictionsDf.where(\"(label = 0 AND prediction = 0) OR  (label = 1 AND prediction = 1)\").count()\nnumInspections = predictionsDf.count()\n\nprint \"There were\", numInspections, \"inspections and there were\", numSuccesses, \"successful predictions\"\nprint \"This is a\", str((float(numSuccesses) / float(numInspections)) * 100) + \"%\", \"success rate\""],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":["# Visualization"],"metadata":{}},{"cell_type":"code","source":["truePositive = int(predictionsDf.where(\"(label = 1 AND prediction = 1)\").count())\ntrueNegative = int(predictionsDf.where(\"(label = 0 AND prediction = 0)\").count())\nfalsePositive = int(predictionsDf.where(\"(label = 0 AND prediction = 1)\").count())\nfalseNegative = int(predictionsDf.where(\"(label = 1 AND prediction = 0)\").count())\n\nprint [['TP', truePositive], ['TN', trueNegative], ['FP', falsePositive], ['FN', falseNegative]]\nresultDF = sqlContext.createDataFrame([['TP', truePositive], ['TN', trueNegative], ['FP', falsePositive], ['FN', falseNegative]], ['metric', 'value'])\ndisplay(resultDF)"],"metadata":{},"outputs":[],"execution_count":20}],"metadata":{"name":"Titanic_BDM_extra_credit","notebookId":1703738175637880},"nbformat":4,"nbformat_minor":0}
